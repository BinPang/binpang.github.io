---
layout: post
title:  "计算最近一段时间的总数量"
date:   2023-05-06
categories: [backend]
---

## 背景
最近在知乎上看到这个问题[后端开发除了增删改查还有什么？](https://www.zhihu.com/question/264370798)

其中我关注的用户大宽宽回答了一下，大宽宽回答的[题目](https://www.zhihu.com/question/264370798/answer/3011389456)有点意思

我拷贝一份 ^_^
1. 需求上需要对部分字段加密，读取时解密。又希望这个逻辑能尽量收敛，避免业务层代码遍地都是加解密，同时又能收敛和管控加密的算法，强度，秘钥等。要怎么做？进一步的：
   1. 如果用来加密的服务不是自己开发的，行规要求必须引入第三方服务，每次存储都得带一次rpc怎么办？
   2. 如果用来加解密的rpc临时失败了，要降级吗？还是直接报错？
   3. 有部分获取数据的请求根本就不需要那条被加密的字段，只需要其余几列。能把加解密优化掉吗？
2. 用mysql太慢了，希望改成某种序列化KV，过渡期不能停服，要双写同时又要能保证数据一致要如何做？进一步的
   1. 改成了KV，但KV可能挂，能临时用mysql降级先存着，KV恢复时再写回来。能保证数据不丢吗？
   2. 以上问题如果发生了跨机房，如何设计数据的访问模式呢？
3. 插入时可以保证幂等吗？如果有多次并发的请求从端上发过来（端上可能会重试，可能会bug抽疯），后端能保证只写入一条数据吗？进一步的
   1. 如果这个数据需要支持软删，软删了后还得可以恢复（比如某种回收站功能），能保证同时只有一条”未删除“的数据吗？insert和update set deleted=0能很好的配合不出乱子吗？
4. 两个机房，做主从复制。无论如何主从复制必然有延迟。如果主库机房写入一条订单，还没复制给从库，主库机房挂了怎么办？从库无法得知主库有这么一条记录，切主可能会导致数据丢失（以及接下来的用户的投诉和巨额赔偿）还是说，这个订单必须得到了从库才算”成功”，怎么实现呢？
5. 一个共享文档，十几个人同时改一行文字，这个改的文字最终会变成什么样呢？改动生效的规则和时序怎么算呢？
6. 一个IM，一堆人在同一个群的不同的端上发消息，谁先谁后呢？
   1. 可以用序列号来搞，但这个序列号怎么生成呢？
   2. 单机可以抗下吗？序列号生成器挂掉怎么办？
7. 做一个鉴权系统，需要存取一堆鉴权规则。鉴权时读取即可实现鉴权，比如用户A能不能访问一个文档X。问题是A可能在一个组织架构里，有上级部门；上级的部门又有上级部门。任意一个部门都可以设置访问文档的规则。 如果多级部门各自设了不同的规则（能访问/不能访问），最终落到A上哪个规则生效呢？具体的逻辑怎么写？更进一步的
   1. 这个规则里还带有条件咋办，比如工作日10:00~17:00可访问；其余时间不可访问
   2. 如果规则有特殊处理咋办，比如不可访问时用户可以向上级发一个申请，审批通过后就可以访问了
   3. 用户又要求这个访问规则必须分多个版本。新版本审批后才能替代旧规则。怎么做？
8. 大量对一个微博帖子发了很多赞，这个赞怎么存和保证准确呢？每次 select count(id) ? 进一步的
   1. 假如我们可以允许一定程度的不准（比如超过9999赞，不太准也可以）但要求不能偏的离谱，必须按某种时间间隔去“矫正”。这个矫正怎么触发呢？
   2. 如果矫正需要某种分布式定时器，这个定时器怎么实现呢？单机可以抗下吗？
   3. 如果机器挂了，定时规则没存盘就丢了，能不丢吗？

## 解答

### 问题一：加密问题
1. \[不可行\]最简单的方法就是封装SDK，其实这样是不行的，主要原因是：但是这会带来一个问题加解密的代码是公开的，无法强制升级，管控比较难
2. \[不可行\]将加解密的代码封装成.so文件，其实这样也是不行的，虽然解决了公开的问题，但是不容易升级，而且封装调用.so库在不同的语言处理起来比较麻烦
3. 如果是公司内部的，那么公司内部的机器提供一个二进制文件，监听一个http端口，直接本地调用http接口进行加解密。这样升级非常简单，本地http调用也是非常灵活的

**小问**
1. 上面的第三个方案已经提供了解决方案了
2. 加解密失败怎么处理？既然用到了加解密，就说明这是非常敏感的数据，那么失败了肯定需要直接报错的。
3. 当然可以啦，假设phone是加密字段，不用select *， 而是直接`select name`，

### 问题二：双写问题
在常规的业务上，出现双写，其实我们对一致性要求都不是那么强（比如写mysql成功，写kv失败），一成功一失败的情况比较少，写kv失败时，我们通常手动处理一下就行了。

但是如果对一致性要求比较高，我们就需要用一定的方式来保证一致性了
1. 双写，以mysql为准，同时我们会比较mysql中的数据与kv中的数据是否一致，我们这时始终以mysql为准，如果kv中的数据与mysql中的不一致，修正kv中的数据。当mysql与kv同步完成后，
在某一时刻，我们以kv为准，同时对比mysql与kv中的数据，如果不一致，报警手动处理
2. binlog同步，我们可以订阅mysql的binlog，把mysql的binlog加工后写入kv，当kv与mysql数据(除去延迟)一致后，写mysql，读kv。
    * 写切换方式1，在某一时刻直接切写到kv
    * 写切换方式2，在某一时刻将mysql设置为只读，写mysql失败直接写kv

**注意**：如果不停服几秒，数据还是可能不一致，如果停服几秒(通常低峰期停服<10s是能接受的)，通常是能保证数据一致的
这里有个关键的点就是mysql中的binlog是否已经成功同步到了kv中了，例如：对id=1执行了delete还在binlog中，这时一条id=1的insert直接插入了kv中，
导致了本来是先delete后insert的操作变成了先insert后delete，其实在一般的业务场景下是不存在的。
这个方案也存在一个致命性问题：**无法回滚**

常规互联网服务，我们都会选择方案一，因为失败的概率比较低，能回滚，保证大多数可用(保证几个9，不出大故障，^_^)
如果是支付相关的业务，我们通常都会停服，保障强一致

**小问**
1. 通常不会用mysql来临时缓存着，一般会写入kafka，kv恢复后，消费kafka写kv，能保障不丢。通常会有一些local cache，当核心kv挂了，对业务影响都比较大
2. 如果跨机房，主要是读写在一个机房

### 问题三：幂等问题
这个比较简单，客户端生成一个唯一id带上来就行了，服务端用这个id来去重

**小问**
1. 用事务，加锁即可处理

### 问题四：支付同步问题
这个问题比较偏交易(支付，订单)系统的问题，对交易系统不太了解的童鞋可能没怎么关注，因为我们一般的系统
是不太关注这类的延迟问题。

在交易系统中，通常会使用[半同步复制](https://dev.mysql.com/doc/refman/8.0/en/replication-semisync.html)，主库在事务提交前,需要把binlog同步到
从库，当binlog已经持久化后，从库会给主库一个ACK，主库收到了这个ACK后才会进行commit。即使主库挂了，那么从库也可以恢复而保证一致性

这里存在的几种可能
1. 主库未收到ack挂了，客户端会提示system busy，这时需要看binlog在从库中是否持久化，如果未持久化那么订单失败，如果已持久化订单成功
2. 主库收到ack还未commit时挂了，客户端会收到system busy这种提示，客户端可以直接查询，当主从切换后恢复正常，通常交易系统都会有个幂等的id
3. 主库收到ack commit后挂了，和2类似

### 问题五：版本问题